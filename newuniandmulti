C:\Users\jaya.namgiri\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'
  return mean(axis=axis, dtype=dtype, out=out, **kwargs)
***************************************

import numpy as np
import pandas as pd
from scipy.stats import zscore
from scipy.spatial.distance import mahalanobis
import seaborn as sns
import matplotlib.pyplot as plt

# Load the dataset
# univariant z score 

# Weekly*******************************************************
columns_to_analyze_2 =  ['totalUsage', 'totalUsageDaily', 'totalUsageWeekly','recentlyUsedTime']
data_filtered_2 = data[columns_to_analyze_2].copy()
z_scores_2 = data_filtered_2.apply(zscore)
z_scores_2['uid'] = data['uid']
z_scores_melted_2 = z_scores_2.melt(id_vars=['uid'], var_name='Feature', value_name='Z-Score')
z_scores_melted_2['Plot'] = 'Usage Count'

# Combine both melted dataframes
data_combined = pd.concat([ z_scores_melted_2])

# Combined plot without black lines on bars
plt.figure(figsize=(14, 8))
sns.barplot(x='uid', y='Z-Score', hue='Feature', data=data_combined)
plt.axhline(y=2, color='r', linestyle='--', label='Threshold')
plt.axhline(y=-2, color='r', linestyle='--')
plt.title('Combined Z-Scores by UID Weekly (Threshold = 2)')
plt.xticks(rotation=270)
plt.legend(loc='upper right')
plt.show()




import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from scipy.spatial.distance import mahalanobis

# Weekly metrics to analyze
data_filtered_2 = data[columns_to_analyze_2].copy()

# Standardize the data (Z-scores)
standardized_data = (data_filtered_2 - data_filtered_2.mean()) / data_filtered_2.std()

# Calculate the covariance matrix
cov_matrix = np.cov(standardized_data, rowvar=False)

# Compute the inverse of the covariance matrix
inv_cov_matrix = np.linalg.inv(cov_matrix)

# Calculate Mahalanobis Distance for each data point
mean_distr = standardized_data.mean(axis=0).values
mahalanobis_distances = standardized_data.apply(
    lambda row: mahalanobis(row.values, mean_distr, inv_cov_matrix), axis=1)

# Adding Mahalanobis distances to the dataframe
data['Mahalanobis_Distance'] = mahalanobis_distances

# Visualization
plt.figure(figsize=(14, 8))
sns.barplot(x=data['uid'], y=data['Mahalanobis_Distance'])
plt.axhline(y=2, color='r', linestyle='--', label='Threshold')
plt.axhline(y=-2, color='r', linestyle='--')
plt.title('Mahalanobis Distances by UID Weekly (Threshold = 2)')
plt.xticks(rotation=270)
plt.ylabel('Mahalanobis Distance')
plt.legend(loc='upper right')
plt.show()

import numpy as np
import pandas as pd
from scipy.stats import zscore
from scipy.spatial.distance import mahalanobis
import seaborn as sns
import matplotlib.pyplot as plt

# Load the dataset


# Calculate Z-scores for weekly metrics
data_filtered_2 = data[columns_to_analyze_2].copy()
z_scores_2 = data_filtered_2.apply(zscore)
z_scores_2['uid'] = data['uid']

# Melt the Z-scores dataframe for visualization
z_scores_melted_2 = z_scores_2.melt(id_vars=['uid'], var_name='Feature', value_name='Z-Score')
z_scores_melted_2['Plot'] = 'Usage Count'

# Calculate Mahalanobis Distance for multivariate analysis
# Standardize the data (Z-scores)
standardized_data = (data_filtered_2 - data_filtered_2.mean()) / data_filtered_2.std()

# Calculate the covariance matrix
cov_matrix = np.cov(standardized_data, rowvar=False)

# Compute the inverse of the covariance matrix
inv_cov_matrix = np.linalg.inv(cov_matrix)

# Calculate Mahalanobis Distance for each data point
mean_distr = standardized_data.mean(axis=0).values
mahalanobis_distances = standardized_data.apply(
    lambda row: mahalanobis(row.values, mean_distr, inv_cov_matrix), axis=1)

# Adding Mahalanobis distances to the dataframe
data['Mahalanobis_Distance'] = mahalanobis_distances

# Identify anomalies based on Z-score threshold
anomaly_z_score_uids = z_scores_2[
                                  (z_scores_2['totalUsage'].abs() > 2) |
                                  (z_scores_2['totalUsageDaily'].abs() > 2) |
                                  (z_scores_2['totalUsageWeekly'].abs() > 2) |
                                  (z_scores_2['recentlyUsedTime'].abs() > 2)]['uid'].unique()

# Identify anomalies based on Mahalanobis Distance threshold
anomaly_mahalanobis_uids = data[data['Mahalanobis_Distance'] > 2]['uid'].unique()

# Combine both sets of anomalies
combined_anomaly_uids = np.intersect1d(anomaly_z_score_uids, anomaly_mahalanobis_uids)


# Display the dataframe with anomalies and Mahalanobis distances
# import ace_tools as tools
# tools.display_dataframe_to_user(name="Anomalies and Mahalanobis Distances", dataframe=data)

# Print the results
print("Anomalies based on Z-Scores:", anomaly_z_score_uids)
print("Anomalies based on Mahalanobis Distance:", anomaly_mahalanobis_uids)
print("Combined Anomalies (Both Z-Scores and Mahalanobis Distance):", combined_anomaly_uids.tolist())




********************************************

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import zscore

# Load the CSV file
file_path = '/mnt/data/sampled_vaedb_Data.csv'
data = pd.read_csv(file_path)

# Columns of interest
columns_of_interest = [
    'totalUsageWeekly', 
    'backgroundTimeWeekly', 
    'rxBytesWifiWeekly', 
    'txBytesWifiWeekly', 
    'powerUsageWeekly'
]

# Extracting relevant columns
data_of_interest = data[columns_of_interest + ['uid']]

# Calculating z-scores
zscores = data_of_interest.apply(zscore)

# Finding outliers using IQR
def find_outliers_iqr(data, column):
    Q1 = data[column].quantile(0.25)
    Q3 = data[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    return data[(data[column] < lower_bound) | (data[column] > upper_bound)]

# Finding outliers using IQR for each column of interest
iqr_outliers = pd.concat([find_outliers_iqr(data, column) for column in columns_of_interest])

# Getting unique uids for IQR outliers
iqr_outlier_uids = iqr_outliers['uid'].unique()

# Finding outliers with z-score threshold of 2
zscore_outliers = zscores[(zscores > 2) | (zscores < -2)]

# Getting unique uids for Z-score outliers
zscore_outlier_uids = data_of_interest['uid'][zscore_outliers.any(axis=1)].unique()

# Melting the data for box plots
melted_data = data.melt(id_vars=['uid'], value_vars=columns_of_interest, var_name='Metric', value_name='Value')

# Box plot
plt.figure(figsize=(10, 6))
sns.boxplot(x='Metric', y='Value', data=melted_data)
plt.title('Box Plots of Selected Columns')
plt.xlabel('Metrics')
plt.ylabel('Values')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# Melting the z-score data for bar plots with UID on x-axis
melted_zscores_uid = zscores.melt(id_vars=['uid'], value_vars=columns_of_interest, var_name='Metric', value_name='Z-Score')

# Bar plot of z-scores with UID on x-axis
plt.figure(figsize=(18, 6))
sns.barplot(x='uid', y='Z-Score', hue='Metric', data=melted_zscores_uid)
plt.axhline(y=2, color='r', linestyle='--', label='Threshold = 2')
plt.axhline(y=-2, color='r', linestyle='--')
plt.title('Z-Score Bar Plots of Selected Columns by UID')
plt.xlabel('UID')
plt.ylabel('Z-Score')
plt.legend(title='Metric')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# Display IQR outliers UIDs
print("IQR Outlier UIDs:", iqr_outlier_uids)

# Display Z-score outliers UIDs
print("Z-score Outlier UIDs:", zscore_outlier_uids)

import ace_tools as tools; tools.display_dataframe_to_user(name="IQR Outlier UIDs", dataframe=pd.DataFrame(iqr_outlier_uids, columns=["UID"]))
tools.display_dataframe_to_user(name="Z-Score Outlier UIDs", dataframe=pd.DataFrame(zscore_outlier_uids, columns=["UID"]))



import pandas as pd
import numpy as np
from scipy.spatial.distance import mahalanobis
from scipy.stats import chi2

# Load the CSV file
file_path = '/mnt/data/sampled_vaedb_Data.csv'
data = pd.read_csv(file_path)

# Columns of interest
columns_of_interest = [
    'totalUsageWeekly', 
    'backgroundTimeWeekly', 
    'rxBytesWifiWeekly', 
    'txBytesWifiWeekly', 
    'powerUsageWeekly'
]

# Extracting relevant columns
data_of_interest = data[columns_of_interest + ['uid']]

# Function to calculate Mahalanobis distance
def mahalanobis_distance(x=None, data=None, cov=None):
    x_mu = x - np.mean(data)
    inv_covmat = np.linalg.inv(cov)
    left_term = np.dot(x_mu, inv_covmat)
    mahal = np.dot(left_term, x_mu.T)
    return mahal.diagonal()

# Data for Mahalanobis distance calculation
data_for_mahal = data_of_interest[columns_of_interest].dropna()

# Calculate covariance matrix
cov_matrix = np.cov(data_for_mahal, rowvar=False)

# Calculate Mahalanobis distance for each observation
data_for_mahal['Mahalanobis_Dist'] = mahalanobis_distance(x=data_for_mahal, data=data_for_mahal, cov=cov_matrix)

# Calculate threshold for identifying outliers (using chi-square distribution, p-value = 0.01)
threshold = np.sqrt(chi2.ppf((1-0.01), df=len(columns_of_interest)))

# Identify outliers
mahalanobis_outliers = data_for_mahal[data_for_mahal['Mahalanobis_Dist'] > threshold]

# Get unique UIDs of outliers
mahalanobis_outlier_uids = data_of_interest.loc[mahalanobis_outliers.index, 'uid'].unique()

# Display outlier UIDs
print("Mahalanobis Outlier UIDs:", mahalanobis_outlier_uids)

import ace_tools as tools; tools.display_dataframe_to_user(name="Mahalanobis Outlier UIDs", dataframe=pd.DataFrame(mahalanobis_outlier_uids, columns=["UID"]))

kakakak
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import zscore
from scipy.spatial.distance import mahalanobis
from scipy.stats import chi2
import numpy as np

# Load the CSV file
file_path = '/mnt/data/sampled_vaedb_Data.csv'
data = pd.read_csv(file_path)

# Columns of interest
columns_of_interest = [
    'totalUsageWeekly', 
    'backgroundTimeWeekly', 
    'rxBytesWifiWeekly', 
    'txBytesWifiWeekly', 
    'powerUsageWeekly'
]

# Extracting relevant columns
data_of_interest = data[columns_of_interest + ['uid']]

# Calculating z-scores only for columns of interest
zscores = data_of_interest[columns_of_interest].apply(zscore)

# Finding outliers using IQR
def find_outliers_iqr(data, column):
    Q1 = data[column].quantile(0.25)
    Q3 = data[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    return data[(data[column] < lower_bound) | (data[column] > upper_bound)]

# Finding outliers using IQR for each column of interest
iqr_outliers = pd.concat([find_outliers_iqr(data, column) for column in columns_of_interest])

# Getting unique uids for IQR outliers
iqr_outlier_uids = iqr_outliers['uid'].unique()

# Finding outliers with z-score threshold of 2
zscore_outliers = zscores[(zscores > 2) | (zscores < -2)]

# Getting unique uids for Z-score outliers
zscore_outlier_uids = data_of_interest['uid'][zscore_outliers.any(axis=1)].unique()

# Melting the data for box plots
melted_data = data.melt(id_vars=['uid'], value_vars=columns_of_interest, var_name='Metric', value_name='Value')

# Box plot
plt.figure(figsize=(10, 6))
sns.boxplot(x='Metric', y='Value', data=melted_data)
plt.title('Box Plots of Selected Columns')
plt.xlabel('Metrics')
plt.ylabel('Values')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# Melting the z-score data for bar plots with UID on x-axis
melted_zscores_uid = pd.concat([data_of_interest[['uid']], zscores], axis=1).melt(id_vars=['uid'], value_vars=columns_of_interest, var_name='Metric', value_name='Z-Score')

# Bar plot of z-scores with UID on x-axis
plt.figure(figsize=(18, 6))
sns.barplot(x='uid', y='Z-Score', hue='Metric', data=melted_zscores_uid)
plt.axhline(y=2, color='r', linestyle='--', label='Threshold = 2')
plt.axhline(y=-2, color='r', linestyle='--')
plt.title('Z-Score Bar Plots of Selected Columns by UID')
plt.xlabel('UID')
plt.ylabel('Z-Score')
plt.legend(title='Metric')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# Display IQR outliers UIDs
print("IQR Outlier UIDs:", iqr_outlier_uids)

# Display Z-score outliers UIDs
print("Z-score Outlier UIDs:", zscore_outlier_uids)

import ace_tools as tools; tools.display_dataframe_to_user(name="IQR Outlier UIDs", dataframe=pd.DataFrame(iqr_outlier_uids, columns=["UID"]))
tools.display_dataframe_to_user(name="Z-Score Outlier UIDs", dataframe=pd.DataFrame(zscore_outlier_uids, columns=["UID"]))

# Multivariate Outlier Detection using Mahalanobis Distance
# Function to calculate Mahalanobis distance
def mahalanobis_distance(x=None, data=None, cov=None):
    x_mu = x - np.mean(data)
    inv_covmat = np.linalg.inv(cov)
    left_term = np.dot(x_mu, inv_covmat)
    mahal = np.dot(left_term, x_mu.T)
    return mahal.diagonal()

# Data for Mahalanobis distance calculation
data_for_mahal = data_of_interest[columns_of_interest].dropna()

# Calculate covariance matrix
cov_matrix = np.cov(data_for_mahal, rowvar=False)

# Calculate Mahalanobis distance for each observation
data_for_mahal['Mahalanobis_Dist'] = mahalanobis_distance(x=data_for_mahal, data=data_for_mahal, cov=cov_matrix)

# Calculate threshold for identifying outliers (using chi-square distribution, p-value = 0.01)
threshold = np.sqrt(chi2.ppf((1-0.01), df=len(columns_of_interest)))

# Identify outliers
mahalanobis_outliers = data_for_mahal[data_for_mahal['Mahalanobis_Dist'] > threshold]

# Get unique UIDs of outliers
mahalanobis_outlier_uids = data_of_interest.loc[mahalanobis_outliers.index, 'uid'].unique()

# Plotting Mahalanobis distances for each UID
plt.figure(figsize=(12, 6))
plt.bar(data_of_interest.index, data_for_mahal['Mahalanobis_Dist'])
plt.axhline(y=threshold, color='r', linestyle='--', label='Outlier Threshold')
plt.title('Mahalanobis Distances by UID')
plt.xlabel('Index')
plt.ylabel('Mahalanobis Distance')
plt.legend()
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# Display outlier UIDs for Mahalanobis Distance
print("Mahalanobis Outlier UIDs:", mahalanobis_outlier_uids)

tools.display_dataframe_to_user(name="Mahalanobis Outlier UIDs", dataframe=pd.DataFrame(mahalanobis_outlier_uids, columns=["UID"]))
