mo# univariant 

import numpy as np
import pandas as pd 
import scipy as stats

data = {'score': [91, 93, 72, 87, 86, 73, 68, 87, 78, 99, 95, 76, 84, 96, 76, 80, 83, 84, 73, 74],
        'hours': [16, 6, 3, 1, 2, 3, 2, 5, 2, 5, 2, 3, 4, 3, 3, 3, 4, 3, 4, 4],
        'prep': [3, 4, 0, 3, 4, 0, 1, 2, 1, 2, 3, 3, 3, 2, 2, 2, 3, 3, 2, 2],
        'grade': [70, 88, 80, 83, 88, 84, 78, 94, 90, 93, 89, 82, 95, 94, 81, 93, 93, 90, 89, 89]
        }

df = pd.DataFrame(data,columns=['score', 'hours', 'prep','grade'])
# df.head()
#create function to calculate Mahalanobis distance
def mahalanobis(x=None, data=None, cov=None):

    x_mu = x - np.mean(data)
    if not cov:
        cov = np.cov(data.values.T)
    inv_covmat = np.linalg.inv(cov)
    left = np.dot(x_mu, inv_covmat)
    mahal = np.dot(left, x_mu.T)
    return mahal.diagonal()

#create new column in dataframe that contains Mahalanobis distance for each row
df['mahalanobis'] = mahalanobis(x=df, data=df[['score', 'hours', 'prep', 'grade']])

#display first five rows of dataframe
df.head()





















# Weekly*******************************************************
columns_to_analyze_2 = ['totalUsageWeekly', 'backgroundTimeWeekly', 'rxBytesWifiWeekly','txBytesWifiWeekly','powerUsageWeekly']
data_filtered_2 = data[columns_to_analyze_2].copy()
z_scores_2 = data_filtered_2.apply(zscore)
z_scores_2['uid'] = data['uid']
z_scores_melted_2 = z_scores_2.melt(id_vars=['uid'], var_name='Feature', value_name='Z-Score')
z_scores_melted_2['Plot'] = 'Usage Count'

# Combine both melted dataframes
data_combined = pd.concat([ z_scores_melted_2])

# Combined plot without black lines on bars
plt.figure(figsize=(14, 8))
sns.barplot(x='uid', y='Z-Score', hue='Feature', data=data_combined)
plt.axhline(y=2, color='r', linestyle='--', label='Threshold')
plt.axhline(y=-2, color='r', linestyle='--')
plt.title('Combined Z-Scores by UID Weekly (Threshold = 2)')
plt.xticks(rotation=270)
plt.legend(loc='upper right')
plt.show()


import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from scipy.spatial.distance import mahalanobis

# Weekly metrics to analyze
columns_to_analyze_2 = ['totalUsageWeekly', 'backgroundTimeWeekly', 'rxBytesWifiWeekly', 'txBytesWifiWeekly', 'powerUsageWeekly']
data_filtered_2 = data[columns_to_analyze_2].copy()

# Standardize the data (Z-scores)
standardized_data = (data_filtered_2 - data_filtered_2.mean()) / data_filtered_2.std()

# Calculate the covariance matrix
cov_matrix = np.cov(standardized_data, rowvar=False)

# Compute the inverse of the covariance matrix
inv_cov_matrix = np.linalg.inv(cov_matrix)

# Calculate Mahalanobis Distance for each data point
mean_distr = standardized_data.mean(axis=0).values
mahalanobis_distances = standardized_data.apply(
    lambda row: mahalanobis(row.values, mean_distr, inv_cov_matrix), axis=1)

# Adding Mahalanobis distances to the dataframe
data['Mahalanobis_Distance'] = mahalanobis_distances

# Visualization
plt.figure(figsize=(14, 8))
sns.barplot(x=data['uid'], y=data['Mahalanobis_Distance'])
plt.axhline(y=2, color='r', linestyle='--', label='Threshold')
plt.axhline(y=-2, color='r', linestyle='--')
plt.title('Mahalanobis Distances by UID Weekly (Threshold = 2)')
plt.xticks(rotation=270)
plt.ylabel('Mahalanobis Distance')
plt.legend(loc='upper right')
plt.show()














# Select relevant columns for multivariate analysis
selected_columns = ['backgroundTimeWeekly', 'foregroundTimeWeekly', 'powerUsageWeekly', 'screenPowerUsageWeekly']

# Step 1: Standardize the Data (Z-scores)
standardized_data = (data[selected_columns] - data[selected_columns].mean()) / data[selected_columns].std()

# Step 2: Calculate the Covariance Matrix
cov_matrix = np.cov(standardized_data, rowvar=False)

# Step 3: Compute the Inverse of the Covariance Matrix
inv_cov_matrix = np.linalg.inv(cov_matrix)

# Step 4: Calculate the Mahalanobis Distance for each data point
mean_distr = standardized_data.mean(axis=0).values
mahalanobis_distances = standardized_data.apply(
    lambda row: mahalanobis(row.values, mean_distr, inv_cov_matrix), axis=1)

# Adding Mahalanobis distances to the dataframe
data['Mahalanobis_Distance'] = mahalanobis_distances

# Display results
import ace_tools as tools
tools.display_dataframe_to_user(name="Multivariate Anomaly Scores", dataframe=data)





import matplotlib.pyplot as plt

# Histogram of Mahalanobis Distances
plt.figure(figsize=(10, 6))
plt.hist(data['Mahalanobis_Distance'], bins=30, edgecolor='k', alpha=0.7)
plt.title('Histogram of Mahalanobis Distances')
plt.xlabel('Mahalanobis Distance')
plt.ylabel('Frequency')
plt.show()

# Box Plot of Mahalanobis Distances
plt.figure(figsize=(10, 6))
plt.boxplot(data['Mahalanobis_Distance'], vert=False)
plt.title('Box Plot of Mahalanobis Distances')
plt.xlabel('Mahalanobis Distance')
plt.show()

# Scatter Plot of Two Selected Features with Anomalies Highlighted
plt.figure(figsize=(10, 6))
plt.scatter(data['backgroundTimeWeekly'], data['foregroundTimeWeekly'], 
            c=data['Mahalanobis_Distance'], cmap='viridis', edgecolor='k')
plt.colorbar(label='Mahalanobis Distance')
plt.title('Scatter Plot of Background Time Weekly vs Foreground Time Weekly')
plt.xlabel('Background Time Weekly')
plt.ylabel('Foreground Time Weekly')
plt.show



all jay 

import numpy as np
import pandas as pd
from scipy.stats import zscore
from scipy.spatial.distance import mahalanobis
import seaborn as sns
import matplotlib.pyplot as plt

# Load the dataset
file_path = '/mnt/data/normalised_final (2).csv'
data = pd.read_csv(file_path)

# Calculate Z-scores for weekly metrics
columns_to_analyze_2 = ['totalUsageWeekly', 'backgroundTimeWeekly', 'rxBytesWifiWeekly', 'txBytesWifiWeekly', 'powerUsageWeekly']
data_filtered_2 = data[columns_to_analyze_2].copy()
z_scores_2 = data_filtered_2.apply(zscore)
z_scores_2['uid'] = data['uid']

# Melt the Z-scores dataframe for visualization
z_scores_melted_2 = z_scores_2.melt(id_vars=['uid'], var_name='Feature', value_name='Z-Score')
z_scores_melted_2['Plot'] = 'Usage Count'

# Calculate Mahalanobis Distance for multivariate analysis
# Standardize the data (Z-scores)
standardized_data = (data_filtered_2 - data_filtered_2.mean()) / data_filtered_2.std()

# Calculate the covariance matrix
cov_matrix = np.cov(standardized_data, rowvar=False)

# Compute the inverse of the covariance matrix
inv_cov_matrix = np.linalg.inv(cov_matrix)

# Calculate Mahalanobis Distance for each data point
mean_distr = standardized_data.mean(axis=0).values
mahalanobis_distances = standardized_data.apply(
    lambda row: mahalanobis(row.values, mean_distr, inv_cov_matrix), axis=1)

# Adding Mahalanobis distances to the dataframe
data['Mahalanobis_Distance'] = mahalanobis_distances

# Identify anomalies based on Z-score threshold
anomaly_z_score_uids = z_scores_2[(z_scores_2['totalUsageWeekly'].abs() > 2) |
                                  (z_scores_2['backgroundTimeWeekly'].abs() > 2) |
                                  (z_scores_2['rxBytesWifiWeekly'].abs() > 2) |
                                  (z_scores_2['txBytesWifiWeekly'].abs() > 2) |
                                  (z_scores_2['powerUsageWeekly'].abs() > 2)]['uid'].unique()

# Identify anomalies based on Mahalanobis Distance threshold
anomaly_mahalanobis_uids = data[data['Mahalanobis_Distance'] > 2]['uid'].unique()

# Combine both sets of anomalies
combined_anomaly_uids = np.intersect1d(anomaly_z_score_uids, anomaly_mahalanobis_uids)

# Visualization
# Histogram of Mahalanobis Distances
plt.figure(figsize=(10, 6))
plt.hist(data['Mahalanobis_Distance'], bins=30, edgecolor='k', alpha=0.7)
plt.title('Histogram of Mahalanobis Distances')
plt.xlabel('Mahalanobis Distance')
plt.ylabel('Frequency')
plt.show()

# Box Plot of Mahalanobis Distances
plt.figure(figsize=(10, 6))
plt.boxplot(data['Mahalanobis_Distance'], vert=False)
plt.title('Box Plot of Mahalanobis Distances')
plt.xlabel('Mahalanobis Distance')
plt.show()

# Scatter Plot of Two Selected Features with Anomalies Highlighted
plt.figure(figsize=(10, 6))
plt.scatter(data['backgroundTimeWeekly'], data['foregroundTimeWeekly'], 
            c=data['Mahalanobis_Distance'], cmap='viridis', edgecolor='k')
plt.colorbar(label='Mahalanobis Distance')
plt.title('Scatter Plot of Background Time Weekly vs Foreground Time Weekly')
plt.xlabel('Background Time Weekly')
plt.ylabel('Foreground Time Weekly')
plt.show()

# Display the dataframe with anomalies and Mahalanobis distances
import ace_tools as tools
tools.display_dataframe_to_user(name="Anomalies and Mahalanobis Distances", dataframe=data)

# Print the results
print("Anomalies based on Z-Scores:", anomaly_z_score_uids)
print("Anomalies based on Mahalanobis Distance:", anomaly_mahalanobis_uids)
print("Combined Anomalies (Both Z-Scores and Mahalanobis Distance):", combined_anomaly_uids.tolist())



7777
import numpy as np
import pandas as pd
from scipy.stats import zscore, chi2
from scipy.spatial.distance import mahalanobis
import seaborn as sns
import matplotlib.pyplot as plt

# Load the dataset
# Assuming your data is already loaded into a DataFrame called `data`

# Columns to analyze
columns_to_analyze_2 = ['totalUsage', 'totalUsageDaily', 'totalUsageWeekly', 'recentlyUsedTime']
data_filtered_2 = data[columns_to_analyze_2].copy()

# Calculate Z-scores for weekly metrics
z_scores_2 = data_filtered_2.apply(zscore)
z_scores_2['uid'] = data['uid']

# Melt the Z-scores dataframe for visualization
z_scores_melted_2 = z_scores_2.melt(id_vars=['uid'], var_name='Feature', value_name='Z-Score')
z_scores_melted_2['Plot'] = 'Usage Count'

# Calculate Mahalanobis Distance for multivariate analysis
# Standardize the data (Z-scores)
standardized_data = (data_filtered_2 - data_filtered_2.mean()) / data_filtered_2.std()

# Calculate the covariance matrix
cov_matrix = np.cov(standardized_data, rowvar=False)

# Compute the inverse of the covariance matrix
inv_cov_matrix = np.linalg.inv(cov_matrix)

# Calculate Mahalanobis Distance for each data point
mean_distr = standardized_data.mean(axis=0).values
mahalanobis_distances = standardized_data.apply(
    lambda row: mahalanobis(row.values, mean_distr, inv_cov_matrix), axis=1)

# Adding Mahalanobis distances to the dataframe
data['Mahalanobis_Distance'] = mahalanobis_distances

# Determine the threshold using chi-squared distribution
degrees_of_freedom = data_filtered_2.shape[1]
threshold = np.sqrt(chi2.ppf(0.95, degrees_of_freedom))

# Identify anomalies based on Z-score threshold
anomaly_z_score_uids = z_scores_2[
    (z_scores_2['totalUsage'].abs() > 2) |
    (z_scores_2['totalUsageDaily'].abs() > 2) |
    (z_scores_2['totalUsageWeekly'].abs() > 2) |
    (z_scores_2['recentlyUsedTime'].abs() > 2)]['uid'].unique()

# Identify anomalies based on Mahalanobis Distance threshold
anomaly_mahalanobis_uids = data[data['Mahalanobis_Distance'] > threshold]['uid'].unique()

# Combine both sets of anomalies
combined_anomaly_uids = np.intersect1d(anomaly_z_score_uids, anomaly_mahalanobis_uids)

# Display the dataframe with anomalies and Mahalanobis distances
# import ace_tools as tools
# tools.display_dataframe_to_user(name="Anomalies and Mahalanobis Distances", dataframe=data)

# Print the results
print("Anomalies based on Z-Scores:", anomaly_z_score_uids)
print("Anomalies based on Mahalanobis Distance:", anomaly_mahalanobis_uids)
print("Combined Anomalies (Both Z-Scores and Mahalanobis Distance):", combined_anomaly_uids.tolist())

# Plot Z-scores
plt.figure(figsize=(14, 8))
sns.barplot(x='uid', y='Z-Score', hue='Feature', data=z_scores_melted_2)
plt.axhline(y=2, color='r', linestyle='--', label='Threshold')
plt.axhline(y=-2, color='r', linestyle='--')
plt.title('Combined Z-Scores by UID Weekly (Threshold = 2)')
plt.xticks(rotation=270)
plt.legend(loc='upper right')
plt.show()

# Plot Mahalanobis Distances with threshold
plt.figure(figsize=(14, 8))
sns.barplot(x=data['uid'], y=data['Mahalanobis_Distance'])
plt.axhline(y=threshold, color='r', linestyle='--', label=f'Threshold = {threshold:.2f}')
plt.title('Mahalanobis Distances by UID Weekly (Chi-squared Threshold)')
plt.xticks(rotation=270)
plt.ylabel('Mahalanobis Distance')
plt.legend(loc='upper right')
plt.show()
